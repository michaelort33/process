{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Scraping Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopy.distance\n",
    "from ipysheet import from_dataframe\n",
    "from ftplib import FTP\n",
    "import fileinput\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display\n",
    "import IPython\n",
    "\n",
    "#regrssion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db = 'zip_test_8'\n",
    "site_url = 'giow1012.siteground.us'\n",
    "port = 21\n",
    "password = 'Mooose33'\n",
    "username = 'michaelort@ortpropertygroup.com'\n",
    "site_folder = '/scrapes/final_database_frames'\n",
    "\n",
    "\n",
    "def read_current_db(site_url, port, username, password, site_folder,\n",
    "                    current_db):\n",
    "    # connect\n",
    "    ftp = FTP()\n",
    "    ftp.set_debuglevel(2)\n",
    "    ftp.connect(site_url, port)\n",
    "    ftp.login(username, password)\n",
    "    ftp.cwd(site_folder)\n",
    "    # read\n",
    "    r = BytesIO()\n",
    "    ftp.retrbinary('RETR {}'.format(current_db + '.pkl'), r.write)\n",
    "    r.seek(0)\n",
    "    old = pickle.load(r)\n",
    "    r.close\n",
    "    ftp.close()\n",
    "    return old\n",
    "\n",
    "\n",
    "#df = read_current_db(site_url, port, username, password, site_folder, current_db)\n",
    "#df.to_pickle('../housing_data/data/final_database_frames/zip_test_7.pkl')\n",
    "df = pd.read_pickle('../housing_data/data/final_database_frames/' + current_db +\n",
    "                    '.pkl')\n",
    "\n",
    "# change name of city to scraped city so that i can have my own city column extracted\n",
    "# from state_city zip\n",
    "df = df.rename(columns={'city': 'scraped_city'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read third party data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/airbnb_analysis/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (3,5,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "location_data = pd.read_csv(\n",
    "    '../housing_data/data/geographic_data/zip_code_database_cleaned.csv',\n",
    "    converters={'zip': lambda x: str(x)})\n",
    "\n",
    "# get population by zip\n",
    "pop_data = pd.read_pickle('../housing_data/data/geographic_data/population_zipcode.pkl')\n",
    "\n",
    "def add_pop_data_to_location_data(pop_data, location_data):\n",
    "    # Add pop data\n",
    "    location_data = location_data.merge(pop_data,left_on='zip',right_on = 'zip_code',how='left')\n",
    "    return location_data\n",
    "\n",
    "location_data = add_pop_data_to_location_data(pop_data, location_data)\n",
    "\n",
    "def get_location_data(location_data):\n",
    "    # read data\n",
    "    location_data = location_data.loc[:, [\n",
    "        'state_city_zip', 'latitude', 'longitude', 'county','pop'\n",
    "    ]]\n",
    "    # create state_city\n",
    "    location_data['state_city'] = location_data.state_city_zip.str.replace(\n",
    "        '\\/\\d+', '')\n",
    "\n",
    "    unique_city_state_location_data = location_data.drop_duplicates(\n",
    "        subset=['state_city'], keep='last')\n",
    "\n",
    "    unique_city_state_location_data = unique_city_state_location_data.drop(\n",
    "        ['state_city_zip','pop'], axis=1)\n",
    "    unique_city_state_location_data = unique_city_state_location_data.rename(columns={'state_city':'state_city_zip'})\n",
    "    city_pops = location_data[['state_city','pop']].groupby(['state_city'],as_index=True).sum()\n",
    "    city_pops.reset_index(level=0,inplace=True)\n",
    "    city_pops = city_pops.rename(columns={'state_city':'state_city_zip'})\n",
    "\n",
    "    unique_city_state_location_data = unique_city_state_location_data.merge(city_pops,on='state_city_zip')\n",
    "    location_data = location_data.drop(['state_city'], axis=1)\n",
    "\n",
    "    return location_data, unique_city_state_location_data\n",
    "\n",
    "\n",
    "location_data, unique_city_state_location_data = get_location_data(\n",
    "    location_data)\n",
    "\n",
    "hotel_data = pd.read_csv(\n",
    "    '../housing_data/2012_census_hotel_accomodation/ECN_2012_US_72Z1_with_ann.csv',\n",
    "    converters={'GEO.id2': lambda x: str(x)},\n",
    "    header=0)\n",
    "\n",
    "\n",
    "def prep_hotel_data(hotel_data):\n",
    "    # filter for all establishments\n",
    "    hotel_data = hotel_data.iloc[1:, :]\n",
    "    hotel_data = hotel_data[hotel_data['RCPSZFE.display-label'] ==\n",
    "                            'All establishments']\n",
    "    hotel_data = hotel_data.drop_duplicates(\n",
    "        ['GEO.id2', 'NAICS.display-label', 'ESTAB'], keep='last')\n",
    "    hotel_data = hotel_data.pivot(index='GEO.id2',\n",
    "                                  columns='NAICS.display-label',\n",
    "                                  values='ESTAB')\n",
    "    hotel_data = hotel_data[[\n",
    "        'Accommodation', 'Bed-and-breakfast inns', 'Casino hotels',\n",
    "        'Hotels (except casino hotels) and motels', 'Traveler accommodation',\n",
    "        'Recreational and vacation camps (except campgrounds)'\n",
    "    ]]\n",
    "    return hotel_data\n",
    "\n",
    "\n",
    "hotel_data = prep_hotel_data(hotel_data)\n",
    "\n",
    "# read zillow data\n",
    "zillow = pd.read_pickle(\n",
    "    '../housing_data/data/zillow/prepped_zillow_data/zillow_19-06.pkl')\n",
    "zillow_city = pd.read_pickle(\n",
    "    '../housing_data/data/zillow/prepped_zillow_data/zillow_19-06_City_.pkl')\n",
    "# change zillow_city to state city zip because that is id column for both cities and zips here\n",
    "\n",
    "zillow_city = zillow_city.rename(columns={'state_city':'state_city_zip'})\n",
    "\n",
    "\n",
    "# read hud data\n",
    "hud = pd.read_pickle(\n",
    "    '../housing_data/data/real_estate/HUD_zip_40_percentile.pkl')\n",
    "\n",
    "# listing data for reviews\n",
    "#listing_data = pd.read_json('../housing_data/data/listing_data/scraped_listings_9_27.json')\n",
    "\n",
    "# Read search results\n",
    "search_results = pd.read_csv(\n",
    "    '../housing_data/data/search_results/research_results.csv',converters={'zip': lambda x: str(x)})\n",
    "\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "\n",
    "def search_results_clean(col):\n",
    "    col = col.str.lower()\n",
    "    col = col.str.replace(' ','-')\n",
    "    return col\n",
    "\n",
    "def prep_search_results(search_results):\n",
    "    search_results = search_results.dropna(subset=['city'])\n",
    "    search_results.loc[:,['state','city']] = search_results[['state','city']].apply(search_results_clean, axis=0)\n",
    "    state_city_zips = []\n",
    "    for row in search_results.iterrows():\n",
    "        state_city_zip = ''\n",
    "        if not row[1]['state']=='':\n",
    "            state_city_zip += row[1]['state']\n",
    "            if not row[1]['city']=='':\n",
    "                state_city_zip += '/'+row[1]['city']\n",
    "                if not row[1]['zip']=='':\n",
    "                    state_city_zip += '/'+row[1]['zip'] \n",
    "        state_city_zips.append(state_city_zip)\n",
    "    search_results['state_city_zip'] = state_city_zips\n",
    "    return search_results[['legal_ranking', 'notes', 'state_city_zip','finalists']]\n",
    "\n",
    "\n",
    "search_results = prep_search_results(search_results)\n",
    "\n",
    "df = df.merge(search_results, on = 'state_city_zip',how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Zillow, Hotel, and Zip Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns_for_merging(df):\n",
    "    df['zip'] = df.state_city_zip.str.extract(r'(\\d+)')\n",
    "    df['zip_data'] = df.state_city_zip.str.contains(r'\\d', regex=True)\n",
    "    df['state_city'] = df.state_city_zip.str.replace('\\/\\d+', '')\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_columns_for_merging(df)\n",
    "\n",
    "\n",
    "def add_zillow_data(df, zillow, zillow_city):\n",
    "    city_data = df[~df.zip_data].reset_index().merge(\n",
    "        zillow_city, on='state_city_zip',how='left').set_index('index')\n",
    "    zip_data = df[df.zip_data].reset_index().merge(\n",
    "        zillow, on='state_city_zip', how='left').set_index('index')\n",
    "    df = pd.concat([city_data, zip_data], axis=0).sort_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_zillow_data(df, zillow, zillow_city)\n",
    "\n",
    "df = df.merge(hotel_data, left_on='zip', right_on='GEO.id2', how='left')\n",
    "\n",
    "# This is really to add location data\n",
    "df = add_zillow_data(df, location_data, unique_city_state_location_data)\n",
    "\n",
    "\n",
    "def add_hud_estimate(hud, zillow):\n",
    "    zillow['zip'] = zillow.state_city_zip.str.extract(r'(\\d+)')\n",
    "    hud['median_rent_hud'] = hud.iloc[:, 3:].mean(axis=1)\n",
    "    zillow_hud = hud[['zcta', 'median_rent_hud']].merge(zillow[['zip', 'Zri']],\n",
    "                                                        left_on='zcta',\n",
    "                                                        right_on='zip',\n",
    "                                                        how='inner')\n",
    "    zillow_hud = zillow_hud.dropna()\n",
    "    lin_reg_mod = linear_model.LinearRegression()\n",
    "    lin_reg_mod.fit(zillow_hud['median_rent_hud'].values.reshape(-1, 1),\n",
    "                    zillow_hud['Zri'].values.reshape(-1, 1))\n",
    "    hud['adjusted_median_rent_hud'] = lin_reg_mod.predict(\n",
    "        hud.median_rent_hud.values.reshape(-1, 1))\n",
    "    return hud\n",
    "\n",
    "\n",
    "def add_hud_data(df, hud):\n",
    "    hud = hud[['zcta', 'median_rent_hud', 'adjusted_median_rent_hud']].merge(df[['zip', 'state_city_zip', 'state_city']],\n",
    "                    left_on='zcta',\n",
    "                    right_on='zip')\n",
    "    hud_city = hud[['state_city', 'median_rent_hud', 'adjusted_median_rent_hud']].groupby(['state_city'],as_index=False).mean()\n",
    "    hud_city = hud_city.rename(columns={'state_city':'state_city_zip'})\n",
    "\n",
    "        \n",
    "    hud = hud[['state_city_zip', 'median_rent_hud', 'adjusted_median_rent_hud']]\n",
    "    df = add_zillow_data(df, hud, hud_city)\n",
    "    return df\n",
    "\n",
    "\n",
    "# add hud estimated rent\n",
    "hud = add_hud_estimate(hud, zillow)\n",
    "\n",
    "# add hud data\n",
    "df = add_hud_data(df, hud)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/airbnb_analysis/lib/python3.7/site-packages/ipykernel_launcher.py:40: DeprecationWarning: Vincenty is deprecated and is going to be removed in geopy 2.0. Use `geopy.distance.geodesic` (or the default `geopy.distance.distance`) instead, which is more accurate and always converges.\n"
     ]
    }
   ],
   "source": [
    "def get_history_extrapolations(my_history):\n",
    "    avg = []\n",
    "    cv = []\n",
    "\n",
    "    for i in my_history:\n",
    "        if type(i) is list:\n",
    "            if len(i) > 0:\n",
    "                avg.append(np.average(i))\n",
    "                cv.append(np.std(i) / np.average(i))\n",
    "            else:\n",
    "                avg.append(np.nan)\n",
    "                cv.append(np.nan)\n",
    "        else:\n",
    "            avg.append(np.nan)\n",
    "            cv.append(np.nan)\n",
    "    return avg, cv\n",
    "\n",
    "\n",
    "def get_num_zip_codes(df):\n",
    "    freq_table = df.state_city.value_counts()\n",
    "    num_times = []\n",
    "    for i in df.state_city:\n",
    "        num_times.append(freq_table.loc[i])\n",
    "    return num_times\n",
    "\n",
    "\n",
    "def add_city_column(df):\n",
    "    my_cities_zip = df[df.zip_data].state_city_zip.str.extract('/(.*?)/')\n",
    "    my_cities_city = df[~df.zip_data].state_city_zip.str.extract('/([^/]*)')\n",
    "    city = pd.concat([my_cities_city, my_cities_zip], axis=0).sort_index()\n",
    "    return city\n",
    "\n",
    "\n",
    "def get_distance_from_nyc(long_lat_row):\n",
    "    if np.isnan(long_lat_row[1]) or np.isnan(long_lat_row[0]):\n",
    "        distance = np.nan\n",
    "    else:\n",
    "        new_york_coords = (40.812522, -73.951924)\n",
    "        place = (long_lat_row[1], long_lat_row[0])\n",
    "        distance = geopy.distance.vincenty(place, new_york_coords).mi\n",
    "    return distance\n",
    "\n",
    "\n",
    "\n",
    "def get_annual_change(df):\n",
    "    last_choices = ['q1','q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9','q10', 'q11', 'q12','q13']\n",
    "    df_growth = df[last_choices]\n",
    "    latest_values = []\n",
    "    old_values = []\n",
    "    for row in df_growth.iterrows():\n",
    "        latest_value = np.nan\n",
    "        old_value = np.nan\n",
    "        for idx, i in enumerate(last_choices):\n",
    "            if not isNaN(row[1][idx]):\n",
    "                if idx >4:\n",
    "                    if not isNaN(row[1][idx-4]):\n",
    "                        latest_value = float(row[1][idx])\n",
    "                        old_value = float(row[1][idx-4])\n",
    "                \n",
    "        latest_values.append(latest_value)\n",
    "        old_values.append(old_value)\n",
    "    \n",
    "    estimates = [round(((105.5-i)-(105.5-k))/(105.5-k),3) if ((not isNaN(k)) and (not isNaN(i))) else np.nan for i,k in zip(latest_values,old_values)]\n",
    "    return estimates    \n",
    "\n",
    "\n",
    "def get_scores(df):\n",
    "    df_scaled = df[[\n",
    "            'current_active_listings', 'avg_monthly_revenue',\n",
    "            'seasonality_monthly_revenue', 'my_mean_rent_to_rent',\n",
    "            'distance_from_Eli', 'avg_monthly_occupancy', 'rating_avg','annual_growth_rate'\n",
    "        ]].apply(lambda x: scale(x),axis=0)\n",
    "    \n",
    "    weights = np.array([1,1,-0.5,2,-1,1,-0.5,0.5])\n",
    "    df_scaled = df_scaled.multiply(weights, axis=1)\n",
    "    my_scores = df_scaled.mean(axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    my_scores_scaled = scaler.fit_transform(my_scores.values.reshape(-1,1))*100\n",
    "    return my_scores_scaled\n",
    "\n",
    "\n",
    "def add_extrapolated_revenue(df):\n",
    "    # now that info is finalized add the extrapolated revenue data\n",
    "    svg_columns = ['monthly_revenue', 'nightly_revenue', 'monthly_occupancy']\n",
    "    for col_name in svg_columns:\n",
    "        # average of lists of history of svg\n",
    "        avg, cv = get_history_extrapolations(df[col_name])\n",
    "        df['avg_' + col_name] = avg\n",
    "        # seasonality measure\n",
    "        df['seasonality_' + col_name] = cv\n",
    "\n",
    "    # the multiply by 0.3 comes from 30 days / 100 for occupancy to become a percent between 0-1\n",
    "    df['expected_avg_monthly_revenue'] = (df['avg_nightly_revenue'].mul(\n",
    "        df['avg_monthly_occupancy'])).apply(lambda x: x * .3)\n",
    "\n",
    "    # divide revenue by rooms and guests to get average per room and per guest\n",
    "    df['revenue_per_room'] = df['avg_monthly_revenue'].divide(df['rooms'])\n",
    "\n",
    "    df['expected_revenue_per_room'] = df['expected_avg_monthly_revenue'].divide(\n",
    "        df['rooms'])\n",
    "\n",
    "    df['expected_revenue_per_guest'] = df[\n",
    "        'expected_avg_monthly_revenue'].divide(df['guests'])\n",
    "\n",
    "    df['listing_growth_percent_quarter'] = [\n",
    "        float(i[0])\n",
    "        for i in df.quarterly_growth.str.extract(r'((?:-\\d)|(?:\\d+))').values\n",
    "    ]\n",
    "    df['percent_full_time'] = [\n",
    "        float(i)\n",
    "        for i in df.pct_available_full_time.str.extract(r'(\\d+)').values\n",
    "    ]\n",
    "    df['percent_entire_home_available'] = [\n",
    "        float(i) for i in df.percent_entire_listing.str.extract(r'(\\d+)').values\n",
    "    ]\n",
    "    df['rating_avg'] = [float(i) for i in df.rating_avg.values]\n",
    "\n",
    "    df['num_zips_in_place'] = get_num_zip_codes(df)\n",
    "\n",
    "    df['state'] = df.state_city_zip.str.extract('(.*?)/')\n",
    "\n",
    "    df['city'] = add_city_column(df)\n",
    "\n",
    "    # put in hud data where zri is missing\n",
    "    df['Zri_hud'] = df[['Zri', 'adjusted_median_rent_hud'\n",
    "                       ]].apply(lambda row: row['adjusted_median_rent_hud']\n",
    "                                if np.isnan(row['Zri']) else row['Zri'],\n",
    "                                axis=1)\n",
    "\n",
    "    df['rent_to_rent_sqft'] = df.revenue_per_room.divide(\n",
    "        df['ZriPerSqft_AllHomes2019-06'].apply(lambda x: x * 670))\n",
    "    df['rent_to_rent_expected_sqft'] = df.expected_revenue_per_room.divide(\n",
    "        df['ZriPerSqft_AllHomes2019-06'].apply(lambda x: x * 670))\n",
    "    df['rent_to_rent'] = df.avg_monthly_revenue.divide(df['Zri_hud'])\n",
    "    df['rent_to_rent_expected'] = df.expected_avg_monthly_revenue.divide(\n",
    "        df['Zri_hud'])\n",
    "    df['my_mean_rent_to_rent'] = df[[\n",
    "        'rent_to_rent', 'rent_to_rent_expected', 'rent_to_rent_sqft',\n",
    "        'rent_to_rent_expected_sqft'\n",
    "    ]].mean(axis=1)\n",
    "\n",
    "    # add distance to zip data\n",
    "    df['distance_from_Eli'] = df[['longitude',\n",
    "                                  'latitude']].apply(get_distance_from_nyc,\n",
    "                                                     axis=1)\n",
    "    \n",
    "    df['annual_growth_rate'] = get_annual_change(df)\n",
    "    \n",
    "    df['score'] = get_scores(df) \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_extrapolated_revenue(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for widgets and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered df for qgrid\n",
    "filtered_df = df[[True if not isNaN(i) else False for i in df.avg_revenue_svg]]\n",
    "filtered_df = filtered_df[[\n",
    "    True if not isNaN(i) else False for i in filtered_df.legal_ranking\n",
    "]]\n",
    "filtered_df['score_f'] = get_scores(filtered_df)\n",
    "\n",
    "# subset from df to use as qgrid frame\n",
    "my_qgrid = filtered_df[[\n",
    "    'state', 'county', 'city', 'zip', 'legal_ranking','current_active_listings', 'rooms',\n",
    "    'expected_avg_monthly_revenue', 'seasonality_monthly_revenue',\n",
    "    'my_mean_rent_to_rent', 'score_f', 'distance_from_Eli',\n",
    "    'avg_monthly_occupancy', 'rating_avg', 'annual_growth_rate','pop','notes','longitude','latitude','finalists'\n",
    "]]\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [20, 15]\n",
    "# my_plot=pd.plotting.scatter_matrix(my_qgrid[[\n",
    "#         'current_active_listings', 'expected_avg_monthly_revenue',\n",
    "#         'seasonality_monthly_revenue', 'my_mean_rent_to_rent',\n",
    "#         'distance_from_Eli', 'avg_monthly_occupancy', 'rating_avg','annual_growth_rate','score_f'\n",
    "#     ]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "my_qgrid.to_excel('../process/data/df.xlsx', index=False)\n",
    "my_qgrid.to_pickle('../process/data/df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 10)\n",
    "#my_filtered_grid"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "40px",
    "left": "1580px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
